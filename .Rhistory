#Create model
xgb_mod <- xgboost(data = xgb_train, max.depth = 2, nrounds = 100) #We arbitrarily chose to run this for 100 rounds
pred_y = predict(xgb_mod, xgb_test)
sqrt(mean((exp(test_y) - exp(pred_y))^2))
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
y_pred <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(dat[test_ids,]$Neighborhood, y_pred)
# Model Evaluation
mean(dat[test_ids,]$Neighborhood != y_pred)
cm
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_dat%>%
count(Neighborhood)%>%
mutate(prop=n/sum(n))
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_dat%>%
count(Neighborhood)%>%
mutate(prop=n/sum(n))
tree_dat[train_ids,]%>%
count(Neighborhood)%>%
mutate(prop=n/sum(n))
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_dat%>%
count(Neighborhood)%>%
mutate(prop=n/sum(n))
tree_dat[-train_ids,]%>%
count(Neighborhood)%>%
mutate(prop=n/sum(n))
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
set.seed(2)
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
x <- model.matrix(SalePrice ~ ., dat)[,-1]
y <- dat$SalePrice
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
library('fastDummies')
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggcorrplot)
library(xgboost)
library(tree)
library(glmnet)
library(e1071)
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
best_lam <- cv_out$lambda.min
#find RMSE
grid <- 10^seq(5,-2,length = 100)
ridge_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 0, lambda = grid)
ridge_preds <- predict(ridge_mod, s= best_lam, newx = x[test_ids,])
sqrt(mean((exp(ridge_preds) - exp(y_test))^2))
ridge_final <- glmnet(x, y, alpha = 0, lambda = best_lam)
round(coef(ridge_final), 3)
x <- model.matrix(SalePrice ~ ., dat)[,-1]
y <- dat$SalePrice
knitr::opts_chunk$set(echo=FALSE,message=FALSE, warning=FALSE)
library('fastDummies')
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggcorrplot)
library(xgboost)
library(tree)
library(glmnet)
library(e1071)
original_dat <- read_csv("data/train.csv")
original_dat <- filter(original_dat, SaleCondition == "Normal")
#The code chunk below further trims our original data to include just the features we are interested in:
dat <- original_dat %>%
select(Neighborhood, CentralAir, PavedDrive, GarageFinish, BldgType, HouseStyle, BsmtFinType1,
SalePrice, PoolArea, LotArea, TotalBsmtSF, GarageArea, GrLivArea, FullBath, HalfBath,
BedroomAbvGr, KitchenAbvGr, Fireplaces, OverallQual, OverallCond, YearBuilt, YearRemodAdd, YrSold, PavedDrive)
ggplot(dat, aes(x = LotArea, y = SalePrice)) +
geom_point()
#Average house price over time
dat %>%
group_by(YrSold) %>%
summarise(meanPrice = mean(SalePrice)) %>%
ggplot(., aes(x = YrSold, y = meanPrice)) +
geom_point() + geom_line()
dat$Sold_08 <- as.factor(ifelse(dat$YrSold == '2008', 'Y', 'N'))
dat <- select(dat, -YrSold)
#Histogram of house prices
dat %>%
ggplot(., aes(x = SalePrice)) +
geom_histogram()
dat$SalePrice <- log(dat$SalePrice)
dat %>%
ggplot(., aes(x = SalePrice)) +
geom_histogram()
dat %>%
count(Neighborhood) %>%
ggplot(aes(x = n, y = reorder(Neighborhood, n))) +
geom_bar(stat = "identity") +
labs(title = "Number of Houses in Each Neighborhood",
x = "Number of Houses",
y = "Neighborhood")
dat$Neighborhood <- ifelse(dat$Neighborhood %in% c('NoRidge', 'NridgHt'), 'GrNoRidge', dat$Neighborhood)
other_neighborhoods <- dat %>%
group_by(Neighborhood) %>%
filter(n() < 30) %>%
distinct(Neighborhood)
dat <- dat %>%
filter(! Neighborhood %in% other_neighborhoods$Neighborhood)
corr_mtx <- cor(select_if(dat, is.numeric), use = "pairwise.complete.obs")
ggcorrplot(corr_mtx, # input the correlation matrix
hc.order = FALSE,
type = "upper",
method = "square",
colors = c("tomato2", "white", "springgreen3"))
nrow(filter(dat, YearRemodAdd == YearBuilt))
dat$Remod <- as.factor(ifelse(dat$YearBuilt == dat$YearRemodAdd, 'Y', 'N'))
dat <- select(dat, -YearRemodAdd)
dat$PavedDrive <- ifelse((dat$PavedDrive == "Y"), "Y", "N")
sapply(dat, function(x) sum(is.na(x)))
dat$GarageFinish <- ifelse(is.na(dat$GarageFinish), "NoGar", dat$GarageFinish)
dat$BsmtFinType1 <- ifelse(is.na(dat$BsmtFinType1), "NoBsmt", dat$BsmtFinType1)
mean(exp(dat$SalePrice))
sd(exp(dat$SalePrice))
unscaled_dat<-dat
num_vars <- names(dat %>% select_if(is.numeric))
num_vars <- num_vars[! num_vars == "SalePrice"] #We didn't scale SalePrice because we already added a log transformation
dat[, num_vars] <- scale(dat[, num_vars], center=TRUE, scale=TRUE)
set.seed(1)
n <- nrow(dat)
train_ids <- sample(1:n, .8 * n)
test_ids <- (1:n)[-train_ids]
#Fit model
mod1 <- lm(SalePrice ~ ., dat[train_ids,])
#Make predictions
mod1_preds <- predict(mod1, dat[test_ids,])
#RMSE
sqrt(mean((exp(dat$SalePrice[test_ids]) - exp(mod1_preds)) ^ 2))
coef(mod1)
x <- model.matrix(SalePrice ~ ., dat)[,-1]
y <- dat$SalePrice
x <- model.matrix(SalePrice ~ ., dat)[,-1]
y <- dat$SalePrice
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
best_lam <- cv_out$lambda.min
#find RMSE
grid <- 10^seq(5,-2,length = 100)
ridge_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 0, lambda = grid)
ridge_preds <- predict(ridge_mod, s= best_lam, newx = x[test_ids,])
sqrt(mean((exp(ridge_preds) - exp(y_test))^2))
ridge_final <- glmnet(x, y, alpha = 0, lambda = best_lam)
round(coef(ridge_final), 3)
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
best_lam <- cv_out$lambda.min
#find RMSE
grid <- 10^seq(5,-2,length = 100)
ridge_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 0, lambda = grid)
ridge_preds <- predict(ridge_mod, s= best_lam, newx = x[test_ids,])
sqrt(mean((exp(ridge_preds) - exp(y_test))^2))
ridge_final <- glmnet(x, y, alpha = 0, lambda = best_lam)
sort(coef(ridge_final)
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
best_lam <- cv_out$lambda.min
#find RMSE
grid <- 10^seq(5,-2,length = 100)
ridge_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 0, lambda = grid)
ridge_preds <- predict(ridge_mod, s= best_lam, newx = x[test_ids,])
sqrt(mean((exp(ridge_preds) - exp(y_test))^2))
ridge_final <- glmnet(x, y, alpha = 0, lambda = best_lam)
sort(coef(ridge_final),decreasing=TRUE)
y_test <- y[test_ids]
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 0, nfolds = 10)
best_lam <- cv_out$lambda.min
#find RMSE
grid <- 10^seq(5,-2,length = 100)
ridge_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 0, lambda = grid)
ridge_preds <- predict(ridge_mod, s= best_lam, newx = x[test_ids,])
sqrt(mean((exp(ridge_preds) - exp(y_test))^2))
ridge_final <- glmnet(x, y, alpha = 0, lambda = best_lam)
round(coef(ridge_final), 3)
sort(coef(ridge_final), decreasing=TRUE)
coefs[order(ridge_final$estimate, decreasing = TRUE),]
library(broom)
sort(coef(ridge_final), decreasing=TRUE)
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 1, nfolds = 10)
best_lam <- cv_out$lambda.min
grid <- 10^seq(5,-2,length = 100)
#coefficients
lasso_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 1, lambda = grid)
lasso_coef <- predict(lasso_mod, type = "coefficients", s = best_lam)#[1:18,]
lasso_coef
#RMSE
sqrt(mean((exp(predict(lasso_mod, s= best_lam, newx = x[test_ids,])) - exp(y_test))^2))
cv_out <- cv.glmnet(x[train_ids,], y[train_ids], alpha = 1, nfolds = 10)
best_lam <- cv_out$lambda.min
grid <- 10^seq(5,-2,length = 100)
#coefficients
lasso_mod <- glmnet(x[train_ids,], y[train_ids], alpha = 1, lambda = grid)
lasso_coef <- predict(lasso_mod, type = "coefficients", s = best_lam)#[1:18,]
lasso_coef
#RMSE
sqrt(mean((exp(predict(lasso_mod, s= best_lam, newx = x[test_ids,])) - exp(y_test))^2))
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(dat[test_ids,]$Neighborhood, y_pred)
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(dat[test_ids,]$Neighborhood, y_pred)
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(dat[test_ids,]$Neighborhood, preds)
# Model Evaluation
mean(true=dat[test_ids,]$Neighborhood != y_pred)
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(dat[test_ids,]$Neighborhood, preds)
# Model Evaluation
mean(dat[test_ids,]$Neighborhood != y_pred)
cm
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(true=dat[test_ids,]$Neighborhood, preds)
# Model Evaluation
mean(dat[test_ids,]$Neighborhood != y_pred)
cm
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
prune_house<- prune.misclass(tree_house, best = 9)
plot(prune_house)
text(prune_house,pretty=0,cex=.5)
dat<-unscaled_dat
dat$SalePrice <- exp(dat$SalePrice)
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(true=dat[test_ids,]$Neighborhood, preds)
# Model Evaluation
mean(dat[test_ids,]$Neighborhood != y_pred)
cm
dat<-unscaled_dat
dat$SalePrice <- exp(dat$SalePrice)
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(true=dat[test_ids,]$Neighborhood, preds)
# Model Evaluation
mean(dat[test_ids,]$Neighborhood != y_pred)
cm
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
tree_preds <- predict(tree_house, tree_dat[test_ids,], type = "class")
table(true = tree_dat[test_ids,]$Neighborhood, preds = tree_preds)
mean(tree_dat[test_ids,]$Neighborhood != tree_preds)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
dat<-unscaled_dat
dat$SalePrice <- exp(dat$SalePrice)
# Fitting Naive Bayes Model
classifier_cl <- naiveBayes(Neighborhood ~ ., dat[train_ids,])
#classifier_cl
# Predicting on test data
preds <- predict(classifier_cl, newdata = dat[test_ids,])
# Confusion Matrix
cm <- table(true=dat[test_ids,]$Neighborhood, preds)
# Model Evaluation
mean(dat[test_ids,]$Neighborhood != y_pred)
cm
tree_dat <-dat %>%
mutate_if(is.character, factor)
tree_house<-tree(as.factor(Neighborhood) ~ .,tree_dat[train_ids,])
summary(tree_house)
plot(tree_house)
text(tree_house,pretty=0,cex=.5)
tree_preds <- predict(tree_house, tree_dat[test_ids,], type = "class")
table(true = tree_dat[test_ids,]$Neighborhood, preds = tree_preds)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(1)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(1)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(1)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(2)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(10)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(20)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(1)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
prune_house<- prune.misclass(tree_house, best = 9)
plot(prune_house)
text(prune_house,pretty=0,cex=.5)
prune_pred <- predict(prune_house, tree_dat[test_ids,],
type = "class")
mean(tree_dat[test_ids,]$Neighborhood != prune_pred)
set.seed(2)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
set.seed(3)
cv_house <- cv.tree(tree_house, FUN = prune.misclass, K = 10)
cv_house
data.frame(error_rate = cv_house$dev, size = cv_house$size, k = cv_house$k) %>%
pivot_longer(cols = 2:3, names_to = "var", values_to = "value") %>%
ggplot(., aes(x = value, y = error_rate)) +
geom_point()+
geom_line()+
facet_wrap(~var, scales = "free")
prune_house<- prune.misclass(tree_house, best = 6)
plot(prune_house)
text(prune_house,pretty=0,cex=.5)
prune_pred <- predict(prune_house, tree_dat[test_ids,],
type = "class")
mean(tree_dat[test_ids,]$Neighborhood != prune_pred)
